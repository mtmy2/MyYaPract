Советы по оптимизации запросов
В этом уроке расскажем, как сделать ваши запросы более эффективными.
Общие советы
Используйте ANALYZE
После каждого изменения большого объёма данных рекомендуется делать ANALYZE, чтобы обновить статистику по таблицам и помочь планировщику выбрать более выгодный план запроса. ANALYZE можно использовать в комбинации с ключевым словом VACUUM, например:

VACUUM ANALYZE; 
VACUUM ANALYZE освобождает пространство СУБД от недоступных объектов, а затем проводит анализ и сбор статистики по таблицам. 
Пример
Данные в таблице удалили или обновили. Чтобы повысить производительность и не мешать пользовательским запросам, данные лишь помечаются на удаление, но фактически не убираются. Команда VACUUM принуждает СУБД удалить недоступные объекты.
Измените запрос с множеством значений в IN
Если в запросе есть условие IN с перечислением множества значений, то произойдёт последовательное сканирование — это не всегда выгодно. Лучше находящееся в IN множество положить в хеш-таблицу и искать соответствие с Hash Join. Для этого нужно сделать искусственный JOIN с данными из множества, входящего в IN: положите множество в VALUES и выполните JOIN.

SELECT * 
FROM my_table 
JOIN (VALUES (1),...,(100)) AS v(val) USING (val) 
WHERE id < 10000;
-- Вместо
SELECT * 
FROM my_table 
WHERE id < 10000 AND val IN (1,...,100); 
Используйте LIMIT
Если вы знаете, что в результате вложенного или внешнего запроса необязательно получать все строки, то используйте LIMIT, — это может существенно сократить реальное выполнение запроса.
Не создавайте много индексов
Много индексов не оптимизируют выполнение запроса, так как планировщику нужно будет все эти индексы посмотреть. Прежде чем создать новый индекс, изучите, есть ли уже индексы в этой таблице: может, достаточно изменить их, чтобы запрос стал более оптимальным? Или проверьте с помощью плана, действительно ли запрос стал более производительным с добавлением нового индекса.
Используйте подходящие типы данных
Чем меньше места занимают данные, тем быстрее выполняются запросы.
Избегайте использование подзапросов и функций в условиях JOIN
Иначе при каждой операции сравнения строк из двух таблиц будет выполняться подзапрос или вычисляться значение функции, что несёт дополнительные расходы по CPU и RAM, особенно на таблицах с относительно большим объёмом данных. 
Оптимизация при разовой миграции данных
Отключите AUTO COMMIT
Каждый запрос в PostgreSQL по умолчанию выполняется в отдельной транзакции. На создание и фиксирование транзакции тратятся дополнительные ресурсы, поэтому все операции с транзакциями в скрипте миграции могут значительно снизить производительность кода. Отключите AUTO COMMIT и в начале скрипта напишите команду BEGIN (начало транзакции), в конце или отдельной части — COMMIT (фиксация транзакции). Так количество операций с транзакциями сократится до минимума.
Как работать с транзакциями в DBeaver

Чтобы использовать транзакции в DBeaver, необязательно каждый раз писать BEGIN TRANSACTION и COMMIT TRANSACTION: команда BEGIN выполняется автоматически, а также есть кнопка переключения в ручной режим управления транзакциями и кнопки Commit и Rollback.

Используйте COPY
Если в скрипте миграции есть INSERT без сложных условий для большого объёма данных, то с точки зрения производительности выгодней использовать COPY. COPY работает быстрее, чем INSERT, на больших объёмах данных, но не такой гибкий. Подробнее можно узнать здесь.
Удалите индексы
Каждый раз, когда новые данные появляются в таблице с индексами, индексы перестраиваются. Это занимает время и ресурсы. Выгоднее сначала перенести в таблицу большой объём информации, а затем на готовых данных построить индексы.
Удалите ограничения внешних ключей
Здесь так же, как и с индексами: выгоднее выполнить все проверки и операции, связанные с внешними ключами на всех данных сразу.
Посмотрите на код DDL, запрос и план запроса ниже. 
DDL: 

CREATE TABLE public.my_table (
    id int8 NOT NULL,
    property_one text NULL,
    property_two text NULL,
    property_three varchar(30) NULL,
    CONSTRAINT my_table_pkey PRIMARY KEY (id)
);
CREATE INDEX my_table_index ON public.my_table USING btree (property_one); 
Запрос:

explain select id from my_table where id = 10000; 
План запроса:

QUERY PLAN                                                                       |
---------------------------------------------------------------------------------+
Index Only Scan using my_table_pkey on my_table  (cost=0.43..4.45 rows=1 width=8)|
  Index Cond: (id = 10000)                                                       | 
Выберите правильное утверждение:


Неправильный ответ
По плану запроса будет использовано последовательное сканирование таблицы my_table.
Надпись Index Only Scan using my_table_pkey в плане запроса говорит о том, что будет произведено сканирование с помощью индекса my_table_pkey по первичному ключу.

Тоже правильный ответ
Средний размер строк, который ожидает планировщик на выводе, равен 8.
Всё так, width=8 — это средний размер строк, который ожидает планировщик.

Время выполнения запроса варьируется от 0.43 до 4.45 миллисекунд.
Существует ещё много тонкостей, которые позволяют писать оптимальные запросы, но большинство из них приходит с опытом и спецификой задачи. С помощью базового анализа запросов можно сравнить скорость их выполнения и попробовать изменить, чтобы сделать более производительными. 
Ещё больше советов по оптимизации вы можете найти в книге «Оптимизация запросов в PostgreSQL» от Домбровской, Новикова и Бейликовой. А пока потренируйтесь оптимизировать в следующем уроке.



